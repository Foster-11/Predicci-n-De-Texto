{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lVwVBMlkw-aQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = keras.models.load_model('autocomplete_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5RzJMdzy8v3",
        "outputId": "20e27590-5130-4350-d21d-842d70f4c31d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ca8b6f5",
        "outputId": "28f42588-8f67-4cd0-94fa-9513161a2057"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# Load the variables from the pickle file\n",
        "with open('autocomplete_variables.pkl', 'rb') as f:\n",
        "    loaded_variables = pickle.load(f)\n",
        "\n",
        "# Assuming you saved the variables as a dictionary or similar structure\n",
        "# You can access them like this:\n",
        "word_to_index = loaded_variables['word_to_index']\n",
        "index_to_word = loaded_variables['index_to_word']\n",
        "max_sequence_length = loaded_variables['max_sequence_length']\n",
        "\n",
        "print(\"Variables loaded successfully!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variables loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95c75576"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "def generate_suggestion(model, tokenizer, max_sequence_length, seed_text, n_words=1):\n",
        "    \"\"\"\n",
        "    Genera la siguiente palabra en una secuencia de texto.\n",
        "\n",
        "    Args:\n",
        "        model: El modelo Keras entrenado.\n",
        "        tokenizer: El tokenizador utilizado para preprocesar los datos.\n",
        "        max_sequence_length: La longitud máxima de las secuencias de entrada.\n",
        "        seed_text: El texto inicial para generar la sugerencia.\n",
        "        n_words: El número de palabras a generar (por defecto es 1).\n",
        "\n",
        "    Returns:\n",
        "        La secuencia de texto con la palabra predicha añadida.\n",
        "    \"\"\"\n",
        "    for _ in range(n_words):\n",
        "        # Preprocesar el texto semilla\n",
        "        token_list = [tokenizer.word_to_index[word] for word in seed_text.split() if word in tokenizer.word_to_index]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "        # Predecir la siguiente palabra\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_word_index = np.argmax(predicted_probs, axis=-1)[0]\n",
        "\n",
        "        # Convertir el índice a palabra\n",
        "        predicted_word = tokenizer.index_to_word.get(predicted_word_index, \"\") # Use .get for safer lookup\n",
        "\n",
        "        # Añadir la palabra predicha al texto semilla\n",
        "        seed_text += \" \" + predicted_word\n",
        "    return seed_text\n",
        "\n",
        "# Nota: Necesitamos crear un \"tokenizer\" que mapee palabras a índices y viceversa.\n",
        "# Usaremos los diccionarios word_to_index y index_to_word que ya creamos.\n",
        "# Podemos crear una clase simple o usar los diccionarios directamente en la función.\n",
        "# Para simplificar, adaptaremos la función para usar los diccionarios existentes."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptar la función de generación para usar los diccionarios existentes\n",
        "def generate_suggestion_adapted(model, word_to_index, index_to_word, max_sequence_length, seed_text, n_words=1):\n",
        "    \"\"\"\n",
        "    Genera la siguiente palabra en una secuencia de texto utilizando diccionarios existentes.\n",
        "\n",
        "    Args:\n",
        "        model: El modelo Keras entrenado.\n",
        "        word_to_index: Diccionario que mapea palabras a índices.\n",
        "        index_to_word: Diccionario que mapea índices a palabras.\n",
        "        max_sequence_length: La longitud máxima de las secuencias de entrada.\n",
        "        seed_text: El texto inicial para generar la sugerencia.\n",
        "        n_words: El número de palabras a generar (por defecto es 1).\n",
        "\n",
        "    Returns:\n",
        "        La secuencia de texto con la palabra predicha añadida.\n",
        "    \"\"\"\n",
        "    for _ in range(n_words):\n",
        "        # Preprocesar el texto semilla\n",
        "        token_list = [word_to_index[word] for word in seed_text.lower().split() if word.lower() in word_to_index]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "        # Predecir la siguiente palabra\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_word_index = np.argmax(predicted_probs, axis=-1)[0]\n",
        "\n",
        "        # Convertir el índice a palabra\n",
        "        predicted_word = index_to_word.get(predicted_word_index, \"\")\n",
        "\n",
        "        # Añadir la palabra predicha al texto semilla\n",
        "        seed_text += \" \" + predicted_word\n",
        "    return seed_text\n",
        "\n",
        "\n",
        "# Solicitar entrada al usuario\n",
        "user_input = input(\"Introduce un fragmento inicial: \")\n",
        "\n",
        "# Generar la sugerencia\n",
        "completed_sentence = generate_suggestion_adapted(new_model, word_to_index, index_to_word, max_sequence_length, user_input, n_words=5) # Generar 5 palabras como ejemplo\n",
        "\n",
        "# Mostrar el resultado completo\n",
        "print(\"Sugerencia completa:\", completed_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jOaannhzijS",
        "outputId": "9a74890b-a8b7-4578-a3ff-93bbd675354c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Introduce un fragmento inicial: How to get a job as sel\n",
            "Sugerencia completa: How to get a job as sel a of canada coast company\n"
          ]
        }
      ]
    }
  ]
}